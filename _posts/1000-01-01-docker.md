---
layout: post
title: Docker
description: Software Engineering
categories: software
tags: container devops
img: docker.png
author: Mason
---

## First thing first - Let's setup Docker
To install docker-ce on Ubuntu, refer to the [web page](https://docs.docker.com/engine/installation/linux/docker-ce/ubuntu/)

## Run Docker

### Hello, Docker!

Basic commands to run images:
```
docker version
docker-compose version
docker-machine version
docker run hello-world
docker search ubuntu:16.04
docker run -ti ubuntu /bin/bash
docker run -d -p 80:80 --name webserver nginx
docker run -p 4000:80 friendlyhello
web browser http://localhost
docker stop webserver
docker start webserver
docker start -a -i $(the name of ubuntu)
docker run --name wp -ti --entrypoint "/bin/bash" arm64/wp
```

What I do want to share with you is the way to properly override a Docker image entrypoint when using docker run.
```
docker run --entrypoint "/bin/ls -al /root" debian
docker: Error: starting container process caused "exec: \"/usr/bin/ls -al\": stat /usr/bin/ls -al: no such file or directory".(not found in $PATH:unkown)
```
Correct it as:
```
docker run --entrypoint "/bin/ls" debian -al /root
```

### Get a load of its existing containers and images

```
docker ps
docker ps -a
docker images
```

Delete containers
```
docker rm -f webserver; docker rm -f $(docker ps -a | grep "\/bin\/sh" | awk '{print $1}')
docker ps --filter "status=exited" | grep 'getstartedlab_web' | awk '{print $1}' | xargs docker rm -f
```
Remove <none> and all stopped containers
Remove all stopped containers.
```
docker rm $(docker ps -a -q)
```
This will remove all stopped containers by getting a list of all containers with docker ps -a -q and passing their ids to docker rm. This should not remove any running containers, and it will tell you it can’t remove a running image.

### Need to run by -p 0000:0000 not only exposing the port in Dockerfile

Run the default Tomcat server (CMD ["catalina.sh", "run"]):
```
docker run -it --rm arm64v8/tomcat:8.0
```

You can test it by visiting http://container-ip:8080 in a browser or, if you need access outside the host, on port 8888:
```
docker run -it --rm -p 8888:8080 arm64v8/tomcat:8.0
```
You can then go to http://localhost:8888 or http://host-ip:8888 in a browser.

If it needs multiple ports, run it as:
```
docker run -it --rm -p 9200:9200 -p 5601:5601 elk6
```

### Use host storage

```
docker volume create my-vol
docker run -d \
  -it \
  --name devtest \
  --mount source=myvol2,target=/app \
  nginx:latest
docker run -d \
  -it \
  --name devtest \
  -v myvol2:/app \
  nginx:latest
docker run -d -p 80 --name website -v $PWD/website:/var/www/html/website james/nginx nginx
```

## Dockerfile

### Use local volume

Dockerfile adds:
```
VOLUME ["/opt/project", '/data/]
```

### User

Dockerfile adds:
```
USER elasticsearch:elasticsearch
COPY --chown=elasticsearch:elasticsearch elasticsearch.yml /usr/share/elasticsearch/config/
RUN su elasticsearch
```

### ADD vs. COPY

> Although ADD and COPY are functionally similar, generally speaking, COPY is preferred. That’s because it’s more transparent than ADD. COPY only supports the basic copying of local files into the container, while ADD has some features (like local-only tar extraction and remote URL support) that are not immediately obvious. Consequently, the best use for ADD is local tar file auto-extraction into the image, as in ADD rootfs.tar.xz /.

> If you have multiple Dockerfile steps that use different files from your context, COPY them individually, rather than all at once. This ensures that each step’s build cache is only invalidated (forcing the step to be re-run) if the specifically required files change.

```
ADD go /usr/local/go
COPY go /usr/local/go
```

## Build images

```
ls
Dockerfile              app.py                  requirements.txt

docker build -t friendlyhello .
docker build --no-cache
docker build -f /path/to/a/Dockerfile .
```

Commit to an image
```
docker commit c3f279d17e0a  svendowideit/testimage:version3
```

Remove all untagged images
In the process of running docker I had accumulated several images that are not tagged. To remove these I use this command:
```
docker rmi $(docker images | grep "^<none>" | awk '{print $3}')
```
This works by using rmi with a list of image ids. To get the image ids we call docker images then pipe it to grep "^<none>". The grep will filter it down to only lines with the value “<none>” in the repository column. Then to extract the id out of the third column we pipe it to awk "{print $3}" which will print the third column of each line passed to it.

## Link containers

### E talks to K by adding --net=elk after creating elk subnet
The new networking feature allows you to connect to containers by their name, so if you create a new network, any container connected to that network can reach other containers by their name. Example:
* Create new network
```
docker network create <network-name>
```
* Connect containers to network
```
docker run --net=<network-name> ...
```
or
```
docker network connect <network-name> <container-name>
```
* Ping container by name
```
docker exec -ti <container-name-A> ping <container-name-B> 
64 bytes from c1 (172.18.0.4): icmp_seq=1 ttl=64 time=0.137 ms
64 bytes from c1 (172.18.0.4): icmp_seq=2 ttl=64 time=0.073 ms
64 bytes from c1 (172.18.0.4): icmp_seq=3 ttl=64 time=0.074 ms
64 bytes from c1 (172.18.0.4): icmp_seq=4 ttl=64 time=0.074 ms
```

So that we could run ELK one by one in the same subnet
```
docker run -ti --rm -p 5601:5601 --net=elk --name k5 arm64/esk-k
docker run -ti --rm -p 9200:9200 --net=elk --name es5 arm64/esk-es
docker run -ti --rm -p 5601:5601 --net=elk --name k6 arm64/elk-k6.0.1
docker run -ti --rm --net=elk arm64/filebeat6.0.1:v3
docker run -ti --rm -p 9200:9200 --net=elk --name es6 arm64/elk-es6.0.1 = docker run -ti --rm -P --net=elk --name es6 arm64/elk-es6.0.1
docker run -ti --rm -v /home/star-111/earthquakes:/earthquakes --net=elk arm64/filebeat6.0.1
```

### Here is another case of WP+MySQL using --link

为WordPress创建数据库
```
docker run -d -P
    --name mysql \
    -e MYSQL_USER=mysql\
    -e MYSQL_PASSWORD=123456 \
    -e MYSQL_DATABASE=HelloWorld  \
    bobsense/mysql
```

在终端下使用下面命令启动mysql
```
mysql -u root -p
```
进入mysql，创建名为wordpress的数据库，并创建用户vamei
```
mysql> CREATE DATABASE wordpress
DEFAULT CHARACTER SET utf8
DEFAULT COLLATE utf8_genercal_ci;
mysql> GRANT SELECT, INSERT, UPDATE, DELETE, CREATE, DROP, INDEX, ALTER, CREATE TEMPORARY TABLES, LOCK TABLES ON wordpress.* TO 'vamei'@'localhost' IDENTIFIED BY 'vameiisgood';
```
vamei的密码为vameiisgood。
```
docker run -d --name wp-db -e MYSQL_DATABASE=wordpress bobsense/mysql
docker run --name wp --link bobsense/mysql:wp-sql -p 8080:80 -d arm64/wp
```
## Swarm

```
dockerd &
docker swarm init --advertise-addr <MANAGER-IP>
docker swarm join --token SWMTKN-1-4ocnq3wmxbf8ghzvix8124o3jjma1t64xm83nfpo9dw6fk1pre-3csiia8whvz5osceis2lgjmwb 10.5.21.111:2377
docker node ls
```

Run a three-task Nginx service on 10-node swarm
```
docker service create --name my_web \
                        --replicas 3 \
                        --publish published=8080,target=80 \
                        arm64v8/nginx
```
REPLICAS 3/3:
my_web.1 swarm.manager, while my_web.2~3 running on swarm.worker as the image `arm64v8/nginx` could be got onto the worker.

```
docker service create --name my_web --replicas 3 --publish published=80,target=80 friendlyhello
docker service create --name my_web --replicas 3 --publish published=80,target=80  --with-registry-auth localhost:5000/mason/python_web
```

Run a nginx web server service on every swarm node
```
docker service create \
  --mode global \
  --publish mode=host,target=80,published=8080 \
  --name=nginx \
  arm64v8/nginx
```
REPLICAS 2/2:
ngnix.xxx is running on swarm.manager, while ngnix.xxx running on swarm.worker as the image `arm64v8/nginx` could be got onto the worker.

Then both 10.5.21.111:8080 and 10.5.21.118:8080 work well
```
docker service rm my_web
docker stack deploy -c docker-compose.yml getstartedlab
docker service ls
docker service ps getstartedlab_web
docker container ls -q
(after changing replicas)docker stack deploy -c docker-compose.yml getstartedlab
docker stack rm getstartedlab
docker swarm leave --force
```

docker-compose.yml:
```
version: "3"
services:
web:

  # replace username/repo:tag with your name and image details
  image: friendlyhello
  deploy:
    replicas: 5
    resources:
      limits:
        cpus: "0.1"
        memory: 50M
    restart_policy:
      condition: on-failure
  ports:
    - "80:80"
  networks:
    - webnet
networks:
webnet:
```

Run your new load-balanced app
```
docker stack deploy -c docker-compose.yml getstartedlab
```
REPLICAS 5/5:
getstartedlab_web.1~5 swarm.manager, while worker rejects it saying "No such image: friendlyhello"

## Docker registry

Errors in building [docker-registry](https://github.com/docker/docker-registry) on ARM:
```
 In file included from gevent/libev.h:2:0,
                     from gevent/gevent.core.c:313:
    libev/ev.c:45:22: fatal error: config.h: No such file or directory
    compilation terminated.
    error: command 'aarch64-linux-gnu-gcc' failed with exit status 1
```

Here is [an alternative](https://github.com/coreos/registry-monitor), but there are still errors:
```
Step 2/12 : RUN apk add --no-cache curl git gcc
 ---> Running in 7f5726b0543d
/bin/sh: 1: apk: not found
The command '/bin/sh -c apk add --no-cache curl git gcc' returned a non-zero code: 127
```

Install your Registry (on your server or locally)
Docker-Registry is a simple Python app, installing it is straight-forward:
```
git clone https://github.com/dotcloud/docker-registry.git
cd docker-registry
cp config_sample.yml config.yml
pip install -r requirements.txt
gunicorn --access-logfile - --log-level debug --debug
    -b 0.0.0.0:5000 -w 1 wsgi:application
```

## Things to learn

- [x] to stack deploy on more phsical machines, if it is possible
- [ ] to compare swarm networking with kubernetes'
